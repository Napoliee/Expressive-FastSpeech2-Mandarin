import os
import librosa
import numpy as np
from scipy.io import wavfile
from tqdm import tqdm
from collections import defaultdict
import json
import random
from pypinyin import lazy_pinyin, Style

from text import _clean_text


def get_sorted_items(items):
    """æŒ‰é”®æ’åº"""
    return sorted(items, key=lambda x: x[0])


def chinese_to_pinyin(text):
    """å°†ä¸­æ–‡è½¬æ¢ä¸ºæ‹¼éŸ³ï¼ˆæ— å£°è°ƒï¼‰"""
    try:
        # ç§»é™¤æ ‡ç‚¹ç¬¦å·ï¼Œåªä¿ç•™ä¸­æ–‡å­—ç¬¦
        chinese_chars = ''.join([char for char in text if '\u4e00' <= char <= '\u9fff'])
        
        if not chinese_chars:
            return ""
        
        # è½¬æ¢ä¸ºæ‹¼éŸ³ï¼ˆæ— å£°è°ƒï¼‰
        pinyin_list = lazy_pinyin(
            chinese_chars,
            style=Style.NORMAL  # ä½¿ç”¨æ— å£°è°ƒæ ¼å¼
        )
        
        # ç”¨ç©ºæ ¼è¿æ¥æ‹¼éŸ³
        pinyin_text = " ".join(pinyin_list)
        return pinyin_text
        
    except Exception as e:
        print(f"âŒ æ‹¼éŸ³è½¬æ¢å¤±è´¥: {text} - {str(e)}")
        return ""


def prepare_align(config):
    """ä¸ºESDä¸­æ–‡æ•°æ®é›†å‡†å¤‡MFAå¯¹é½æ‰€éœ€çš„æ–‡ä»¶ï¼ŒåŒ¹é…preprocessor_en.pyæ ¼å¼"""
    
    in_dir = config["path"]["corpus_path"]
    out_dir = config["path"]["raw_path"]
    sampling_rate = config["preprocessing"]["audio"]["sampling_rate"]
    max_wav_value = config["preprocessing"]["audio"]["max_wav_value"]
    cleaners = config["preprocessing"]["text"]["text_cleaners"]
    val_ratio = config["preprocessing"].get("val_ratio", 0.15)
    test_ratio = config["preprocessing"].get("test_ratio", 0.05)
    
    print("ğŸ¯ å¼€å§‹å‡†å¤‡ESDä¸­æ–‡æ•°æ®é›†ï¼ˆæ‹¼éŸ³æ ¼å¼ï¼ŒåŒ¹é…preprocessor_en.pyæ ¼å¼ï¼‰...")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(out_dir, exist_ok=True)
    
    # æƒ…ç»ªæ˜ å°„ï¼ˆä¸­æ–‡åˆ°è‹±æ–‡ï¼‰
    emotion_mapping_cn = {
        "ä¸­ç«‹": "Neutral",
        "å¼€å¿ƒ": "Happy", 
        "ä¼¤å¿ƒ": "Sad",
        "æ„¤æ€’": "Angry",
        "æƒŠè®¶": "Surprise"
    }
    
    # æƒ…ç»ªåˆ°æ•°å€¼çš„æ˜ å°„ï¼ˆç”¨äºarousalå’Œvalenceï¼‰
    emotion_values = {
        "Neutral": {"arousal": "0.5", "valence": "0.5"},
        "Happy": {"arousal": "0.8", "valence": "0.8"},
        "Sad": {"arousal": "0.3", "valence": "0.2"},
        "Angry": {"arousal": "0.9", "valence": "0.1"},
        "Surprise": {"arousal": "0.8", "valence": "0.6"}
    }
    
    # å­˜å‚¨æ‰€æœ‰æ–‡ä»¶ä¿¡æ¯
    all_files_info = []
    speaker_info = {}
    
    # ç»Ÿè®¡è½¬æ¢æƒ…å†µ
    total_files = 0
    converted_files = 0
    
    # åªå¤„ç†ä¸­æ–‡è¯´è¯äººï¼ˆ0001-0010ï¼‰
    for speaker_id in range(1, 11):  # 0001-0010ä¸ºä¸­æ–‡
        speaker_folder = f"{speaker_id:04d}"
        source_speaker_dir = os.path.join(in_dir, speaker_folder)
        
        if not os.path.exists(source_speaker_dir):
            continue
            
        print(f"ğŸ“‚ å¤„ç†ä¸­æ–‡è¯´è¯äºº: {speaker_folder}")
        
        # è¯»å–æ–‡æœ¬æ–‡ä»¶
        text_file = os.path.join(source_speaker_dir, f"{speaker_folder}.txt")
        if not os.path.exists(text_file):
            print(f"âŒ æ‰¾ä¸åˆ°æ–‡æœ¬æ–‡ä»¶: {text_file}")
            continue
            
        # è§£ææ–‡æœ¬æ–‡ä»¶
        text_dict = {}
        with open(text_file, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    parts = line.strip().split('\t')
                    if len(parts) >= 3:
                        file_id, text, emotion_cn = parts[0], parts[1], parts[2]
                        emotion_en = emotion_mapping_cn.get(emotion_cn, "Neutral")
                        text_dict[file_id] = {
                            'text': text,
                            'emotion_cn': emotion_cn,
                            'emotion_en': emotion_en
                        }
        
        # è®°å½•è¯´è¯äººä¿¡æ¯ï¼ˆå‡è®¾æ€§åˆ«ï¼Œå¯ä»¥æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´ï¼‰
        speaker_info[speaker_folder] = {
            'gender': 'M' if speaker_id <= 5 else 'F'  # ç®€å•å‡è®¾å‰5ä¸ªæ˜¯ç”·æ€§
        }
        
        # åˆ›å»ºè¯´è¯äººè¾“å‡ºç›®å½•
        speaker_out_dir = os.path.join(out_dir, speaker_folder)
        os.makedirs(speaker_out_dir, exist_ok=True)
        
        # å¤„ç†æ¯ä¸ªæƒ…ç»ªæ–‡ä»¶å¤¹
        for emotion_folder in ["Angry", "Happy", "Neutral", "Sad", "Surprise"]:
            source_emotion_dir = os.path.join(source_speaker_dir, emotion_folder)
            
            if not os.path.exists(source_emotion_dir):
                continue
                
            # å¤„ç†éŸ³é¢‘æ–‡ä»¶
            wav_files = [f for f in os.listdir(source_emotion_dir) if f.endswith('.wav')]
            
            for wav_file in tqdm(wav_files, desc=f"  {emotion_folder}"):
                file_id = os.path.splitext(wav_file)[0]
                total_files += 1
                
                if file_id in text_dict:
                    # å¤„ç†éŸ³é¢‘æ–‡ä»¶
                    source_wav = os.path.join(source_emotion_dir, wav_file)
                    target_wav = os.path.join(speaker_out_dir, f"{file_id}.wav")
                    
                    # é‡é‡‡æ ·éŸ³é¢‘
                    wav, _ = librosa.load(source_wav, sr=sampling_rate)
                    wav = wav / max(abs(wav)) * max_wav_value
                    wavfile.write(target_wav, sampling_rate, wav.astype(np.int16))
                    
                    # æ¸…ç†æ–‡æœ¬å¹¶è½¬æ¢ä¸ºæ‹¼éŸ³
                    text = text_dict[file_id]['text']
                    cleaned_text = _clean_text(text, cleaners)
                    
                    # è½¬æ¢ä¸ºæ‹¼éŸ³
                    pinyin_text = chinese_to_pinyin(cleaned_text)
                    
                    if not pinyin_text:
                        print(f"âš ï¸  è·³è¿‡ç©ºæ‹¼éŸ³: {cleaned_text}")
                        continue
                    
                    # åˆ›å»ºæ‹¼éŸ³labæ–‡ä»¶
                    target_lab = os.path.join(speaker_out_dir, f"{file_id}.lab")
                    with open(target_lab, 'w', encoding='utf-8') as f:
                        f.write(pinyin_text)
                    
                    # è®°å½•æ–‡ä»¶ä¿¡æ¯ï¼ˆåŒ¹é…preprocessor_en.pyæ ¼å¼ï¼‰
                    emotion_en = emotion_folder
                    emotion_vals = emotion_values[emotion_en]
                    
                    # åˆ›å»ºæ ‡å‡†basenameï¼ˆä¸éŸ³é¢‘æ–‡ä»¶åä¿æŒä¸€è‡´ï¼‰
                    # preprocessorèƒ½å¤Ÿä»basename.split("_")[0]æå–speaker
                    basename = file_id
                    
                    all_files_info.append({
                        'basename': basename,
                        'text': pinyin_text,  # æ‹¼éŸ³æ–‡æœ¬
                        'original_text': cleaned_text,  # ä¿ç•™åŸå§‹ä¸­æ–‡
                        'speaker_id': speaker_folder,
                        'emotion': emotion_en,
                        'arousal': emotion_vals["arousal"],
                        'valence': emotion_vals["valence"]
                    })
                    
                    converted_files += 1
                    
                    # æ˜¾ç¤ºå‰å‡ ä¸ªè½¬æ¢ç¤ºä¾‹
                    if converted_files <= 10:
                        print(f"ğŸ“ ç¤ºä¾‹ {converted_files}: {cleaned_text} â†’ {pinyin_text}")
    
    # åˆ›å»ºpreprocessor_en.pyæ ¼å¼çš„æ–‡ä»¶åˆ—è¡¨
    create_en_style_filelist(out_dir, all_files_info, val_ratio, test_ratio)
    
    # ä¿å­˜è¯´è¯äººä¿¡æ¯ï¼ˆpreprocessor_en.pyæ ¼å¼ï¼‰
    save_en_style_speaker_info(out_dir, speaker_info)
    
    print(f"\nâœ… ESDä¸­æ–‡æ•°æ®é¢„å¤„ç†å®Œæˆï¼ˆæ‹¼éŸ³æ ¼å¼ï¼Œpreprocessor_en.pyæ ¼å¼ï¼‰!")
    print(f"ğŸ“Š æ€»æ–‡ä»¶æ•°: {total_files}")
    print(f"ğŸ”¤ æˆåŠŸè½¬æ¢: {converted_files}")
    print(f"ğŸ‘¥ è¯´è¯äººæ•°: {len(speaker_info)}")
    print(f"ğŸ¯ è¾“å‡ºæ ¼å¼: æ‹¼éŸ³ (ç”¨äºæ‹¼éŸ³MFAæ¨¡å‹)")
    print(f"ğŸ“ æ–‡ä»¶æ ¼å¼: preprocessor_en.pyæ ¼å¼")


def create_en_style_filelist(out_dir, files_info, val_ratio=0.15, test_ratio=0.05):
    """åˆ›å»ºpreprocessor_en.pyæ ¼å¼çš„filelistæ–‡ä»¶"""
    print("ğŸ“ åˆ›å»ºpreprocessor_en.pyæ ¼å¼çš„æ–‡ä»¶åˆ—è¡¨...")
    
    # è®¾ç½®éšæœºç§å­
    random.seed(42)
    
    # æŒ‰è¯´è¯äººå’Œæƒ…ç»ªåˆ†ç»„è¿›è¡Œåˆ†å±‚é‡‡æ ·
    speaker_emotion_groups = defaultdict(lambda: defaultdict(list))
    
    for file_info in files_info:
        speaker_id = file_info['speaker_id']
        emotion = file_info['emotion']
        speaker_emotion_groups[speaker_id][emotion].append(file_info)
    
    train_files = []
    val_files = []
    test_files = []
    
    # ä¸ºæ¯ä¸ªè¯´è¯äººçš„æ¯ç§æƒ…ç»ªè¿›è¡Œåˆ†å±‚é‡‡æ ·
    for speaker_id in speaker_emotion_groups:
        for emotion in speaker_emotion_groups[speaker_id]:
            emotion_files = speaker_emotion_groups[speaker_id][emotion]
            random.shuffle(emotion_files)
            
            n_files = len(emotion_files)
            n_test = max(1, int(n_files * test_ratio))
            n_val = max(1, int(n_files * val_ratio))
            n_train = n_files - n_test - n_val
            
            # åˆ†é…æ–‡ä»¶
            test_files.extend(emotion_files[:n_test])
            val_files.extend(emotion_files[n_test:n_test + n_val])
            train_files.extend(emotion_files[n_test + n_val:])
    
    # åˆ›å»ºpreprocessor_en.pyæ ¼å¼çš„filelistï¼šbasename|text|speaker_id|å…¶ä»–å­—æ®µ|emotion|arousal|valence
    def create_en_style_lines(files):
        lines = []
        for file_info in files:
            line = "|".join([
                file_info['basename'],     # basenameï¼ˆpreprocessorä»è¿™é‡Œæå–ï¼‰
                file_info['text'],         # æ‹¼éŸ³æ–‡æœ¬
                file_info['speaker_id'],   # è¯´è¯äººID
                "esd_chinese",             # æ•°æ®é›†æ ‡è¯†
                "default",                 # å ä½ç¬¦
                file_info['emotion'],      # æƒ…æ„Ÿï¼ˆå€’æ•°ç¬¬3ä¸ªï¼‰
                file_info['arousal'],      # arousalå€¼ï¼ˆå€’æ•°ç¬¬2ä¸ªï¼‰
                file_info['valence']       # valenceå€¼ï¼ˆæœ€åä¸€ä¸ªï¼‰
            ])
            lines.append(line)
        return lines
    
    train_lines = create_en_style_lines(train_files)
    val_lines = create_en_style_lines(val_files)
    test_lines = create_en_style_lines(test_files)
    
    # ä¿å­˜æ–‡ä»¶åˆ—è¡¨
    with open(os.path.join(out_dir, "train.txt"), 'w', encoding='utf-8') as f:
        f.write('\n'.join(train_lines))
    
    with open(os.path.join(out_dir, "val.txt"), 'w', encoding='utf-8') as f:
        f.write('\n'.join(val_lines))
    
    with open(os.path.join(out_dir, "test.txt"), 'w', encoding='utf-8') as f:
        f.write('\n'.join(test_lines))
    
    # ä¿å­˜å®Œæ•´æ–‡ä»¶åˆ—è¡¨ï¼ˆpreprocessor_en.pyæ ¼å¼ï¼‰
    all_lines = train_lines + val_lines + test_lines
    with open(os.path.join(out_dir, "filelist.txt"), 'w', encoding='utf-8') as f:
        f.write('\n'.join(all_lines))
    
    # å¦å¤–ä¿å­˜ä¸€ä¸ªåŒ…å«åŸå§‹ä¸­æ–‡çš„æ˜ å°„æ–‡ä»¶ï¼ˆç”¨äºåç»­å‚è€ƒï¼‰
    mapping_lines = []
    for file_info in files_info:
        mapping_line = f"{file_info['basename']}|{file_info['original_text']}|{file_info['text']}"
        mapping_lines.append(mapping_line)
    
    with open(os.path.join(out_dir, "chinese_pinyin_mapping.txt"), 'w', encoding='utf-8') as f:
        f.write('\n'.join(mapping_lines))
    
    print(f"   ğŸ“Š æ•°æ®åˆ’åˆ†ç»Ÿè®¡:")
    print(f"     è®­ç»ƒé›†: {len(train_lines)} æ¡ç›® ({len(train_lines)/len(all_lines)*100:.1f}%)")
    print(f"     éªŒè¯é›†: {len(val_lines)} æ¡ç›® ({len(val_lines)/len(all_lines)*100:.1f}%)")
    print(f"     æµ‹è¯•é›†: {len(test_lines)} æ¡ç›® ({len(test_lines)/len(all_lines)*100:.1f}%)")
    print(f"   ğŸ“ å·²ä¿å­˜ä¸­æ–‡-æ‹¼éŸ³æ˜ å°„æ–‡ä»¶: chinese_pinyin_mapping.txt")
    print(f"   âœ… filelistæ ¼å¼: basename|text|speaker_id|dataset|default|emotion|arousal|valence")


def save_en_style_speaker_info(out_dir, speaker_info):
    """ä¿å­˜preprocessor_en.pyæ ¼å¼çš„è¯´è¯äººä¿¡æ¯æ–‡ä»¶"""
    print("ğŸ‘¥ ä¿å­˜è¯´è¯äººä¿¡æ¯ï¼ˆpreprocessor_en.pyæ ¼å¼ï¼‰...")
    
    # preprocessor_en.pyæ ¼å¼ï¼šè¯´è¯äººID|å…¶ä»–ä¿¡æ¯
    with open(os.path.join(out_dir, "speaker_info.txt"), 'w', encoding='utf-8') as f:
        for speaker_id, info in get_sorted_items(speaker_info.items()):
            gender = info['gender']
            f.write(f'{speaker_id}|{gender}\n')
    
    print(f"   è®°å½•äº† {len(speaker_info)} ä¸ªè¯´è¯äººä¿¡æ¯")
    print(f"   âœ… speaker_infoæ ¼å¼: è¯´è¯äººID|æ€§åˆ«") 