#!/usr/bin/env python3
"""
æµ‹è¯•ç°æœ‰100kæ¨¡å‹çš„æ¨ç†åŠŸèƒ½ï¼ˆä½¿ç”¨åŸå§‹æ‹¼éŸ³ç³»ç»Ÿï¼‰
"""

import argparse
import os
import torch
import yaml
import numpy as np
from torch.utils.data import DataLoader

from utils.model import get_model, get_vocoder
from utils.tools import to_device, synth_samples
from dataset import TextDataset

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

def preprocess_chinese_pinyin(text, speaker="0001"):
    """
    ç®€å•çš„ä¸­æ–‡åˆ°æ‹¼éŸ³æ˜ å°„ï¼ˆç”¨äºæµ‹è¯•ç°æœ‰æ¨¡å‹ï¼‰
    """
    
    # ç®€å•çš„ä¸­æ–‡è¯å¯¹åº”æ‹¼éŸ³æ˜ å°„
    chinese_to_pinyin = {
        "ä½ å¥½": "ni3 hao3",
        "ä¸–ç•Œ": "shi4 jie4", 
        "ç¾ä¸½": "mei3 li4",
        "ä¸­å›½": "zhong1 guo2",
        "ä»Šå¤©": "jin1 tian1",
        "æ˜å¤©": "ming2 tian1",
        "è°¢è°¢": "xie4 xie4",
        "å¼€å¿ƒ": "kai1 xin1",
        "ç”Ÿæ—¥å¿«ä¹": "sheng1 ri4 kuai4 le4",
    }
    
    # å¦‚æœæ‰¾åˆ°æ˜ å°„å°±ä½¿ç”¨ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤
    if text in chinese_to_pinyin:
        pinyin_text = chinese_to_pinyin[text]
    else:
        # é»˜è®¤æ‹¼éŸ³
        pinyin_text = "ni3 hao3"
    
    return pinyin_text

def synthesize(model, configs, vocoder, batchs, control_values):
    preprocess_config, model_config, train_config = configs
    pitch_control, energy_control, duration_control = control_values

    for batch in batchs:
        batch = to_device(batch, device)
        with torch.no_grad():
            # Forward
            output = model(
                *(batch[2:]),
                p_control=pitch_control,
                e_control=energy_control,
                d_control=duration_control
            )
            synth_samples(
                batch,
                output,
                vocoder,
                model_config,
                preprocess_config,
                train_config["path"]["result_path"],
            )

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--restore_step", type=int, default=100000)
    parser.add_argument("--text", type=str, default="ä½ å¥½", help="æµ‹è¯•æ–‡æœ¬")
    parser.add_argument("--speaker_id", type=str, default="0001", help="speaker ID")
    parser.add_argument("--emotion", type=str, default="å¼€å¿ƒ", help="emotion: å¼€å¿ƒ/ä¼¤å¿ƒ/æƒŠè®¶/æ„¤æ€’/ä¸­ç«‹")
    parser.add_argument("--pitch_control", type=float, default=1.0)
    parser.add_argument("--energy_control", type=float, default=1.0)
    parser.add_argument("--duration_control", type=float, default=1.0)
    args = parser.parse_args()

    # Read Config
    preprocess_config = yaml.load(open("config/ESD-Chinese/preprocess.yaml", "r"), Loader=yaml.FullLoader)
    model_config = yaml.load(open("config/ESD-Chinese/model.yaml", "r"), Loader=yaml.FullLoader)
    train_config = yaml.load(open("config/ESD-Chinese/train.yaml", "r"), Loader=yaml.FullLoader)
    configs = (preprocess_config, model_config, train_config)

    # æ¢å¤åŸå§‹æ¨¡å‹é…ç½®
    model_config["max_seq_len"] = 2000
    if "vocab_size" in model_config:
        del model_config["vocab_size"]  # ç§»é™¤IPAç‰¹å®šé…ç½®

    print(f"ğŸ¤ æµ‹è¯•ç°æœ‰æ¨¡å‹æ¨ç†")
    print(f"æ£€æŸ¥ç‚¹: {args.restore_step}")
    print(f"è¾“å…¥æ–‡æœ¬: {args.text}")
    print(f"è¯´è¯äºº: {args.speaker_id}")
    print(f"æƒ…æ„Ÿ: {args.emotion}")

    # Get model
    model = get_model(args, configs, device, train=False)

    # Load vocoder
    vocoder = get_vocoder(model_config, device)

    # å‡†å¤‡è¾“å…¥æ•°æ®
    ids = [args.speaker_id + "_test"]
    raw_texts = [args.text]
    speakers = np.array([int(args.speaker_id)])
    
    # æƒ…æ„Ÿæ˜ å°„
    emotion_map = {"å¼€å¿ƒ": 0, "ä¼¤å¿ƒ": 1, "æƒŠè®¶": 2, "æ„¤æ€’": 3, "ä¸­ç«‹": 4}
    emotions = np.array([emotion_map.get(args.emotion, 0)])
    arousals = np.array([0.5])
    valences = np.array([0.5])
    
    # è½¬æ¢ä¸ºæ‹¼éŸ³ï¼ˆä½¿ç”¨åŸå§‹æ–‡æœ¬å¤„ç†ç³»ç»Ÿï¼‰
    try:
        from text import text_to_sequence
        pinyin_text = preprocess_chinese_pinyin(args.text, args.speaker_id)
        print(f"æ‹¼éŸ³è½¬æ¢: {pinyin_text}")
        
        texts = [np.array(text_to_sequence(pinyin_text, ["basic_cleaners"]))]
        text_lens = np.array([len(texts[0])])
        
        batchs = [(ids, raw_texts, speakers, emotions, arousals, valences, texts, text_lens, max(text_lens))]

        control_values = args.pitch_control, args.energy_control, args.duration_control

        print(f"ğŸµ å¼€å§‹åˆæˆ...")
        synthesize(model, configs, vocoder, batchs, control_values)
        print(f"âœ… åˆæˆå®Œæˆï¼è¯·æ£€æŸ¥è¾“å‡ºç›®å½•: {train_config['path']['result_path']}")
        
    except Exception as e:
        print(f"âŒ æ¨ç†å¤±è´¥: {e}")
        print("è¿™å¯èƒ½æ˜¯å› ä¸ºç¬¦å·è¡¨ä¸åŒ¹é…ï¼Œå»ºè®®é‡æ–°è®­ç»ƒIPAæ¨¡å‹")

if __name__ == "__main__":
    main() 