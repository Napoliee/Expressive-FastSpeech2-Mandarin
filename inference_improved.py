#!/usr/bin/env python3
"""
æ”¹è¿›çš„æ¨ç†è„šæœ¬ - ä½¿ç”¨æ›´å‡†ç¡®çš„IPAéŸ³ç´ æ˜ å°„
"""

import argparse
import os
import torch
import yaml
import numpy as np
from torch.utils.data import DataLoader

from utils.model import get_model, get_vocoder
from utils.tools import to_device, synth_samples
from text.ipa_processor import text_to_sequence_ipa

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

def create_better_chinese_to_ipa():
    """
    åŸºäºè®­ç»ƒæ•°æ®ä¸­è§‚å¯Ÿåˆ°çš„IPAéŸ³ç´ åˆ›å»ºæ›´å¥½çš„æ˜ å°„
    """
    
    # ä»å®é™…è®­ç»ƒæ•°æ®ä¸­æå–çš„å¸¸è§å­—ç¬¦åˆ°IPAæ˜ å°„
    # è¿™äº›æ˜¯åœ¨MFAå¯¹é½ä¸­å®é™…å‡ºç°çš„éŸ³ç´ 
    char_to_ipa = {
        # å¸¸ç”¨å­—ç¬¦ - åŸºäºå®é™…MFAç»“æœ
        'æˆ‘': ['w', 'oË¨Ë©Ë¦'],
        'ä¸€': ['iË¥Ë©'],
        'ç›´': ['ÊˆÊ‚', 'ÊÌ©Ë§Ë¥'],
        'åˆ°': ['t', 'awË¥Ë©'],
        'æ¸…': ['tÉ•Ê°', 'iÅ‹Ë¥Ë©'],
        'æ™¨': ['tÊ‚Ê°', 'É™nË§Ë¥'],
        'å››': ['s', 'zÌ©Ë¥Ë©'],
        'ç‚¹': ['tj', 'anË¨Ë©Ë¦'],
        'æ‰': ['tsÊ°', 'ajË§Ë¥'],
        'å®¶': ['tÉ•', 'j', 'aË¥Ë©'],
        'ï¼Œ': ['spn'],
        
        'å°±': ['tÉ•', 'j', 'owË¥Ë©'],
        'æ˜¯': ['Ê‚', 'ÊÌ©Ë¥Ë©'],
        'è¿™': ['ÊˆÊ‚', 'É™Ë¥Ë©'],
        'ä¸ª': ['k', 'É™Ë¥Ë©'],
        'æ„': ['iË¥Ë©'],
        'æ€': ['s', 'zÌ©Ë¥Ë©'],
        'ä½ ': ['n', 'iË¨Ë©Ë¦'],
        'åˆ': ['j', 'owË¥Ë©'],
        'èª': ['ts', 'oÅ‹Ë¥Ë©'],
        'æ˜': ['m', 'iÅ‹Ë§Ë¥'],
        'å¥½': ['x', 'awË¨Ë©Ë¦'],
        'çœ‹': ['kÊ°', 'anË¥Ë©'],
        'ã€‚': ['spn'],
        
        'æ‰€': ['s', 'uÌ¯oË¨Ë©Ë¦'],
        'ä»¥': ['iË¨Ë©Ë¦'],
        'æ°¸': ['j', 'oÅ‹Ë¨Ë©Ë¦'],
        'ä¸': ['p', 'uË¥Ë©'],
        'å–': ['x', 'É™Ë¥Ë©'],
        'å®ƒ': ['tÊ°', 'aË¥Ë©'],
        'çš„': ['t', 'iË¥Ë©'],
        
        # æ›´å¤šå¸¸ç”¨å­—ç¬¦
        'äº†': ['l', 'iÌ¯awË¨Ë©Ë¦'],
        'æœ‰': ['j', 'owË¨Ë©Ë¦'],
        'åœ¨': ['ts', 'ajË¥Ë©'],
        'ä¼š': ['x', 'uejË¥Ë©'],
        'è¯´': ['Ê‚', 'uÌ¯oË¥Ë©'],
        'è¦': ['j', 'awË¥Ë©'],
        'éƒ½': ['t', 'owË¥Ë©'],
        'å¾ˆ': ['x', 'É™nË¨Ë©Ë¦'],
        'ä¹Ÿ': ['j', 'eË¨Ë©Ë¦'],
        'å¯': ['kÊ°', 'É™Ë¨Ë©Ë¦'],
        'ä»€': ['Ê‚', 'É™nË§Ë¥'],
        'ä¹ˆ': ['m', 'É™Ë¥Ë©'],
        'æ²¡': ['m', 'ejË§Ë¥'],
        'æ—¶': ['Ê‚', 'ÊÌ©Ë§Ë¥'],
        'å€™': ['x', 'owË¥Ë©'],
        'è¿˜': ['x', 'ajË§Ë¥'],
        'èƒ½': ['n', 'É™Å‹Ë§Ë¥'],
        'å»': ['tÉ•Ê°', 'yË¥Ë©'],
        'æ¥': ['l', 'ajË§Ë¥'],
        'ç”¨': ['j', 'oÅ‹Ë¥Ë©'],
        'é‚£': ['n', 'aË¥Ë©'],
        'äº›': ['É•', 'j', 'eË¥Ë©'],
        'ä¸º': ['w', 'ejË§Ë¥'],
        
        # æ•°å­—
        'é›¶': ['l', 'iÅ‹Ë§Ë¥'],
        'äºŒ': ['ÊŒË§Ë¥', 'ÊÌ©Ë¥Ë©'],
        'ä¸‰': ['s', 'anË¥Ë©'],
        'äº”': ['w', 'uË¨Ë©Ë¦'],
        'å…­': ['l', 'j', 'owË¥Ë©'],
        'ä¸ƒ': ['tÉ•Ê°', 'iË¥Ë©'],
        'å…«': ['p', 'aË¥Ë©'],
        'ä¹': ['tÉ•', 'j', 'owË¨Ë©Ë¦'],
        'å': ['Ê‚', 'ÊÌ©Ë§Ë¥'],
    }
    
    return char_to_ipa

def improved_chinese_to_ipa(text):
    """
    æ”¹è¿›çš„ä¸­æ–‡åˆ°IPAè½¬æ¢
    """
    char_to_ipa = create_better_chinese_to_ipa()
    
    # æ¸…ç†æ–‡æœ¬
    text = text.strip()
    
    ipa_phones = []
    
    for char in text:
        if char in char_to_ipa:
            # ä½¿ç”¨å·²çŸ¥æ˜ å°„
            phones = char_to_ipa[char]
            ipa_phones.extend(phones)
        elif '\u4e00' <= char <= '\u9fff':  # ä¸­æ–‡å­—ç¬¦
            # æœªçŸ¥ä¸­æ–‡å­—ç¬¦ï¼Œä½¿ç”¨ç»Ÿè®¡ä¸Šæœ€å¸¸è§çš„éŸ³ç´ æ¨¡å¼
            # æ ¹æ®ä¸­æ–‡éŸ³éŸµå­¦ï¼Œå¤§å¤šæ•°å­—ç¬¦æ˜¯å£°æ¯+éŸµæ¯ç»“æ„
            import random
            fallback_options = [
                ['Ê‚', 'ÊÌ©Ë¥Ë©'],   # ç±»ä¼¼"æ˜¯"
                ['t', 'iË¥Ë©'],    # ç±»ä¼¼"çš„"
                ['x', 'awË¨Ë©Ë¦'],  # ç±»ä¼¼"å¥½"
                ['l', 'iË¥Ë©'],    # ç±»ä¼¼"æ"
                ['m', 'ejË§Ë¥'],   # ç±»ä¼¼"æ²¡"
                ['n', 'iË¨Ë©Ë¦'],   # ç±»ä¼¼"ä½ "
                ['k', 'É™Ë¥Ë©'],    # ç±»ä¼¼"ä¸ª"
                ['tÉ•', 'iË¥Ë©'],   # ç±»ä¼¼"åŠ"
                ['w', 'oË¨Ë©Ë¦'],   # ç±»ä¼¼"æˆ‘"
                ['j', 'owË¥Ë©'],   # ç±»ä¼¼"æœ‰"
            ]
            chosen_phones = random.choice(fallback_options)
            ipa_phones.extend(chosen_phones)
            print(f"âš ï¸  æœªçŸ¥å­—ç¬¦ '{char}' -> {chosen_phones}")
        elif char in 'ï¼Œã€‚ï¼Ÿï¼ï¼›ï¼šã€':
            # æ ‡ç‚¹ç¬¦å·
            ipa_phones.append('spn')
        elif char.strip():  # éç©ºç™½å­—ç¬¦
            # å…¶ä»–å­—ç¬¦å½“ä½œé™éŸ³
            ipa_phones.append('spn')
    
    # å¦‚æœç»“æœä¸ºç©ºï¼Œæ·»åŠ é»˜è®¤éŸ³ç´ 
    if not ipa_phones:
        ipa_phones = ['n', 'iË¨Ë©Ë¦', 'x', 'awË¨Ë©Ë¦']  # "ä½ å¥½"
    
    # æ·»åŠ å¥é—´åœé¡¿ï¼ˆå¯¹äºé•¿å¥å­ï¼‰
    if len(ipa_phones) > 8:
        enhanced_phones = []
        for i, phone in enumerate(ipa_phones):
            enhanced_phones.append(phone)
            # é€‚å½“ä½ç½®æ·»åŠ åœé¡¿
            if i > 0 and (i + 1) % 6 == 0 and i < len(ipa_phones) - 1:
                enhanced_phones.append('spn')
        ipa_phones = enhanced_phones
    
    return ipa_phones

def get_latest_checkpoint():
    """è·å–æœ€æ–°çš„checkpoint"""
    checkpoint_dir = "output/ckpt/ESD-Chinese"
    if not os.path.exists(checkpoint_dir):
        return None
    
    checkpoints = [f for f in os.listdir(checkpoint_dir) if f.endswith('.pth.tar')]
    if not checkpoints:
        return None
    
    # æ‰¾åˆ°æœ€æ–°çš„checkpoint
    latest_checkpoint = max(checkpoints, key=lambda x: int(x.split('.')[0]))
    return int(latest_checkpoint.split('.')[0])

def synthesize(model, configs, vocoder, batchs, control_values):
    preprocess_config, model_config, train_config = configs
    pitch_control, energy_control, duration_control = control_values

    for batch in batchs:
        batch = to_device(batch, device)
        with torch.no_grad():
            # Forward
            output = model(
                *(batch[2:]),
                p_control=pitch_control,
                e_control=energy_control,
                d_control=duration_control
            )
            synth_samples(
                batch,
                output,
                vocoder,
                model_config,
                preprocess_config,
                train_config["path"]["result_path"],
            )

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--restore_step", type=int, default=None, help="ä½¿ç”¨ç‰¹å®šæ­¥æ•°çš„checkpointï¼Œé»˜è®¤ä½¿ç”¨æœ€æ–°çš„")
    parser.add_argument("--text", type=str, default="ä½ å¥½ä¸–ç•Œ", help="è¦åˆæˆçš„ä¸­æ–‡æ–‡æœ¬")
    parser.add_argument("--speaker_id", type=str, default="0001", help="è¯´è¯äººID")
    parser.add_argument("--emotion", type=str, default="ä¸­ç«‹", help="æƒ…æ„Ÿ: å¼€å¿ƒ/ä¼¤å¿ƒ/æƒŠè®¶/æ„¤æ€’/ä¸­ç«‹")
    parser.add_argument("--pitch_control", type=float, default=1.0)
    parser.add_argument("--energy_control", type=float, default=1.0)
    parser.add_argument("--duration_control", type=float, default=1.0)
    args = parser.parse_args()

    # è·å–æœ€æ–°checkpoint
    if args.restore_step is None:
        latest_step = get_latest_checkpoint()
        if latest_step is None:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•checkpointæ–‡ä»¶")
            return
        args.restore_step = latest_step
        print(f"ğŸ”„ ä½¿ç”¨æœ€æ–°checkpoint: {args.restore_step}")
    
    # Read Config
    preprocess_config = yaml.load(open("config/ESD-Chinese/preprocess.yaml", "r"), Loader=yaml.FullLoader)
    model_config = yaml.load(open("config/ESD-Chinese/model.yaml", "r"), Loader=yaml.FullLoader)
    train_config = yaml.load(open("config/ESD-Chinese/train.yaml", "r"), Loader=yaml.FullLoader)
    configs = (preprocess_config, model_config, train_config)

    print(f"ğŸ¤ æ”¹è¿›ç‰ˆæ¨ç†è„šæœ¬")
    print(f"æ£€æŸ¥ç‚¹: {args.restore_step}")
    print(f"è¾“å…¥æ–‡æœ¬: {args.text}")
    print(f"è¯´è¯äºº: {args.speaker_id}")
    print(f"æƒ…æ„Ÿ: {args.emotion}")

    # Get model
    model = get_model(args, configs, device, train=False)

    # Load vocoder
    vocoder = get_vocoder(model_config, device)

    # è½¬æ¢æ–‡æœ¬ä¸ºIPAéŸ³ç´ 
    ipa_phones = improved_chinese_to_ipa(args.text)
    ipa_text = "{" + " ".join(ipa_phones) + "}"
    
    print(f"IPAéŸ³ç´ åºåˆ—: {ipa_text}")
    print(f"éŸ³ç´ æ•°é‡: {len(ipa_phones)}")

    # å‡†å¤‡è¾“å…¥æ•°æ®
    ids = [args.speaker_id + "_improved"]
    raw_texts = [args.text]
    speakers = np.array([int(args.speaker_id)], dtype=np.int64)
    
    # æƒ…æ„Ÿæ˜ å°„
    emotion_map = {"å¼€å¿ƒ": 0, "ä¼¤å¿ƒ": 1, "æƒŠè®¶": 2, "æ„¤æ€’": 3, "ä¸­ç«‹": 4}
    emotions = np.array([emotion_map.get(args.emotion, 4)], dtype=np.int64)
    arousals = np.array([0.5], dtype=np.float32)
    valences = np.array([0.5], dtype=np.float32)
    
    # è½¬æ¢ä¸ºåºåˆ—
    try:
        text_sequence = np.array(text_to_sequence_ipa(ipa_text), dtype=np.int64)
        text_lens = np.array([len(text_sequence)], dtype=np.int64)
        
        print(f"éŸ³ç´ åºåˆ—é•¿åº¦: {text_lens[0]}")
        print(f"éŸ³ç´ IDåºåˆ—: {text_sequence}")
        
        # å¯¹textsè¿›è¡Œpaddingå¤„ç†
        from utils.tools import pad_1D
        texts = pad_1D([text_sequence])
        
        batchs = [(ids, raw_texts, speakers, emotions, arousals, valences, texts, text_lens, max(text_lens))]

        control_values = args.pitch_control, args.energy_control, args.duration_control

        print(f"ğŸµ å¼€å§‹åˆæˆ...")
        synthesize(model, configs, vocoder, batchs, control_values)
        print(f"âœ… åˆæˆå®Œæˆï¼")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {train_config['path']['result_path']}")
        print(f"ğŸ§ éŸ³é¢‘æ–‡ä»¶: {args.speaker_id}_improved.wav")
        
    except Exception as e:
        print(f"âŒ æ¨ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 