#!/usr/bin/env python3
"""
æ”¶é›†MFAç”Ÿæˆçš„æ‰€æœ‰IPAéŸ³ç´ ï¼Œåˆ›å»ºæ–°çš„ç¬¦å·è¡¨
"""

import os
import textgrid
from collections import Counter
from tqdm import tqdm

def collect_all_ipa_phonemes():
    """ä»æ‰€æœ‰TextGridæ–‡ä»¶ä¸­æ”¶é›†IPAéŸ³ç´ """
    
    print("=== æ”¶é›†MFAç”Ÿæˆçš„æ‰€æœ‰IPAéŸ³ç´  ===")
    
    phoneme_counter = Counter()
    textgrid_dir = "preprocessed_data/ESD-Chinese/TextGrid"
    
    # éå†æ‰€æœ‰TextGridæ–‡ä»¶
    for speaker in os.listdir(textgrid_dir):
        speaker_dir = os.path.join(textgrid_dir, speaker)
        if not os.path.isdir(speaker_dir):
            continue
            
        textgrid_files = [f for f in os.listdir(speaker_dir) if f.endswith('.TextGrid')]
        
        for tg_file in tqdm(textgrid_files, desc=f"å¤„ç†è¯´è¯äºº{speaker}"):
            tg_path = os.path.join(speaker_dir, tg_file)
            
            try:
                tg = textgrid.TextGrid.fromFile(tg_path)
                
                # æŸ¥æ‰¾phoneså±‚
                phone_tier = None
                for tier in tg.tiers:
                    if tier.name.lower() in ['phones', 'phone']:
                        phone_tier = tier
                        break
                
                if phone_tier:
                    for interval in phone_tier:
                        phone = interval.mark.strip()
                        if phone and phone != '':
                            phoneme_counter[phone] += 1
                            
            except Exception as e:
                print(f"è·³è¿‡æ–‡ä»¶ {tg_path}: {e}")
                continue
    
    print(f"\nå‘ç° {len(phoneme_counter)} ä¸ªå”¯ä¸€éŸ³ç´ ")
    print("éŸ³ç´ ä½¿ç”¨é¢‘ç‡ï¼ˆå‰20ä¸ªï¼‰:")
    for phone, count in phoneme_counter.most_common(20):
        print(f"  {phone}: {count}")
    
    return list(phoneme_counter.keys())

def create_ipa_symbols_file(ipa_phonemes):
    """åˆ›å»ºåŸºäºIPAçš„symbols.pyæ–‡ä»¶"""
    
    print(f"\n=== åˆ›å»ºIPAç¬¦å·è¡¨ ===")
    
    # åŸºæœ¬ç¬¦å·
    _pad = "_"
    _punctuation = "!'(),.:;? "
    _special = "-"
    _letters = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz"
    
    # å°†IPAéŸ³ç´ æŒ‰å‰ç¼€åˆ†ç»„ï¼Œæ·»åŠ @å‰ç¼€ç¡®ä¿å”¯ä¸€æ€§
    _ipa_phonemes = ["@" + p for p in sorted(ipa_phonemes)]
    
    # ç”Ÿæˆsymbols.pyå†…å®¹
    symbols_content = f'''""" IPA-based symbols for ESD-Chinese dataset """

_pad = "{_pad}"
_punctuation = "{_punctuation}"
_special = "{_special}"
_letters = "{_letters}"

# IPA phonemes from MFA alignment (with @ prefix for uniqueness)
_ipa_phonemes = {_ipa_phonemes}

# Export all symbols
symbols = (
    [_pad]
    + list(_special)
    + list(_punctuation)
    + list(_letters)
    + _ipa_phonemes
)

# Create symbol to ID mapping
_symbol_to_id = {{s: i for i, s in enumerate(symbols)}}
_id_to_symbol = {{i: s for i, s in enumerate(symbols)}}
'''

    # ä¿å­˜æ–°çš„symbols.py
    with open("text/symbols_ipa.py", "w", encoding="utf-8") as f:
        f.write(symbols_content)
    
    print(f"åˆ›å»ºäº†æ–°çš„ç¬¦å·è¡¨: text/symbols_ipa.py")
    print(f"æ€»ç¬¦å·æ•°: {len(_ipa_phonemes) + len(_pad + _special + _punctuation + _letters)}")
    
    return _ipa_phonemes

def create_ipa_text_processor():
    """åˆ›å»ºIPAæ–‡æœ¬å¤„ç†å™¨"""
    
    ipa_processor_content = '''"""
IPA-based text processing for ESD-Chinese
"""

import re
import numpy as np
from text.symbols_ipa import symbols, _symbol_to_id, _id_to_symbol

# Regular expression matching text enclosed in curly braces:
_curly_re = re.compile(r"(.*?)\\{(.+?)\\}(.*)")

def text_to_sequence_ipa(text, cleaner_names=None):
    """
    Convert IPA phoneme text to sequence of IDs
    
    Args:
        text: IPA phoneme string like "{t w ejË¥Ë© Ê‚ ejË§Ë¥ spn n aË¥Ë©}"
        cleaner_names: ignored for IPA processing
    
    Returns:
        List of integers corresponding to the phonemes
    """
    sequence = []
    
    # Check for curly braces and extract phonemes
    if text.startswith('{') and text.endswith('}'):
        # Extract phonemes from curly braces
        phonemes = text[1:-1].split()
        sequence = _phonemes_to_sequence(phonemes)
    else:
        # Treat as space-separated phonemes
        phonemes = text.split()
        sequence = _phonemes_to_sequence(phonemes)
    
    return sequence

def _phonemes_to_sequence(phonemes):
    """Convert phoneme list to ID sequence"""
    sequence = []
    for phoneme in phonemes:
        # Add @ prefix for IPA phonemes
        ipa_symbol = "@" + phoneme
        if ipa_symbol in _symbol_to_id:
            sequence.append(_symbol_to_id[ipa_symbol])
        else:
            # Unknown phoneme, use a default
            print(f"Warning: Unknown phoneme '{phoneme}', using '@spn'")
            if "@spn" in _symbol_to_id:
                sequence.append(_symbol_to_id["@spn"])
            else:
                sequence.append(1)  # UNK token
    
    return sequence

def sequence_to_text_ipa(sequence):
    """Convert sequence back to text"""
    result = []
    for id in sequence:
        if id < len(symbols):
            symbol = symbols[id]
            if symbol.startswith('@'):
                result.append(symbol[1:])  # Remove @ prefix
            else:
                result.append(symbol)
    return ' '.join(result)
'''

    with open("text/ipa_processor.py", "w", encoding="utf-8") as f:
        f.write(ipa_processor_content)
    
    print("åˆ›å»ºäº†IPAæ–‡æœ¬å¤„ç†å™¨: text/ipa_processor.py")

def create_preprocessing_script():
    """åˆ›å»ºé‡æ–°é¢„å¤„ç†çš„è„šæœ¬"""
    
    script_content = '''#!/usr/bin/env python3
"""
ä½¿ç”¨IPAéŸ³ç´ ç³»ç»Ÿé‡æ–°é¢„å¤„ç†æ•°æ®
"""

import os
import json
import numpy as np
import textgrid
from tqdm import tqdm

def extract_ipa_data():
    """ä»TextGridæå–IPAéŸ³ç´ å’Œæ—¶é•¿ç‰¹å¾"""
    
    print("=== ä½¿ç”¨IPAéŸ³ç´ é‡æ–°é¢„å¤„ç†æ•°æ® ===")
    
    # è¯»å–è¯´è¯äººå’Œæƒ…æ„Ÿæ˜ å°„
    with open("preprocessed_data/ESD-Chinese/speakers.json", "r") as f:
        speaker_map = json.load(f)
    
    with open("preprocessed_data/ESD-Chinese/emotions.json", "r") as f:
        emotion_data = json.load(f)
    
    train_data = []
    val_data = []
    
    textgrid_dir = "preprocessed_data/ESD-Chinese/TextGrid"
    
    for speaker in tqdm(os.listdir(textgrid_dir)):
        speaker_dir = os.path.join(textgrid_dir, speaker)
        if not os.path.isdir(speaker_dir):
            continue
        
        textgrid_files = [f for f in os.listdir(speaker_dir) if f.endswith('.TextGrid')]
        
        for tg_file in textgrid_files:
            basename = tg_file.replace('.TextGrid', '')
            tg_path = os.path.join(speaker_dir, tg_file)
            
            try:
                # æå–IPAéŸ³ç´ å’Œæ—¶é•¿
                result = extract_phonemes_and_duration(tg_path)
                if not result:
                    continue
                
                phonemes, durations = result
                
                # æ£€æŸ¥å¯¹åº”çš„æ–‡æœ¬å’Œæƒ…æ„Ÿ
                original_files = [
                    "preprocessed_data/ESD-Chinese/train_original.txt",
                    "preprocessed_data/ESD-Chinese/val_original.txt"
                ]
                
                text_info = None
                for orig_file in original_files:
                    if os.path.exists(orig_file):
                        text_info = find_text_info(orig_file, basename, speaker)
                        if text_info:
                            break
                
                if not text_info:
                    continue
                
                raw_text, emotion = text_info
                
                # æ„å»ºæ•°æ®è¡Œ
                ipa_phonemes_str = "{" + " ".join(phonemes) + "}"
                data_line = f"{basename}|{speaker}|{ipa_phonemes_str}|{raw_text}|{speaker}|{raw_text}|{emotion}"
                
                # ä¿å­˜ç‰¹å¾æ–‡ä»¶
                save_features(speaker, basename, phonemes, durations)
                
                # åˆ†é…åˆ°è®­ç»ƒé›†æˆ–éªŒè¯é›†ï¼ˆç®€å•åˆ†å‰²ï¼‰
                if len(train_data) < 17000:  # å¤§æ¦‚æ¯”ä¾‹
                    train_data.append(data_line)
                else:
                    val_data.append(data_line)
                    
            except Exception as e:
                print(f"è·³è¿‡ {tg_path}: {e}")
                continue
    
    # ä¿å­˜æ–°çš„æ•°æ®æ–‡ä»¶
    with open("preprocessed_data/ESD-Chinese/train_ipa.txt", "w", encoding="utf-8") as f:
        for line in train_data:
            f.write(line + "\\n")
    
    with open("preprocessed_data/ESD-Chinese/val_ipa.txt", "w", encoding="utf-8") as f:
        for line in val_data:
            f.write(line + "\\n")
    
    print(f"ç”Ÿæˆ {len(train_data)} ä¸ªè®­ç»ƒæ ·æœ¬")
    print(f"ç”Ÿæˆ {len(val_data)} ä¸ªéªŒè¯æ ·æœ¬")

def extract_phonemes_and_duration(textgrid_path):
    """ä»TextGridæå–éŸ³ç´ å’Œæ—¶é•¿"""
    try:
        tg = textgrid.TextGrid.fromFile(textgrid_path)
        phone_tier = None
        
        for tier in tg.tiers:
            if tier.name.lower() in ['phones', 'phone']:
                phone_tier = tier
                break
        
        if phone_tier is None:
            return None
        
        phonemes = []
        durations = []
        
        for interval in phone_tier:
            phone = interval.mark.strip()
            duration_frames = int((interval.maxTime - interval.minTime) * 22050 / 256)
            
            if phone and phone != '':
                phonemes.append(phone)
                durations.append(max(1, duration_frames))
        
        return phonemes, durations
        
    except Exception as e:
        return None

def find_text_info(file_path, basename, speaker):
    """ä»åŸå§‹æ–‡ä»¶ä¸­æŸ¥æ‰¾æ–‡æœ¬å’Œæƒ…æ„Ÿä¿¡æ¯"""
    with open(file_path, "r", encoding="utf-8") as f:
        for line in f:
            parts = line.strip().split("|")
            if len(parts) >= 6 and parts[0] == basename and parts[1] == speaker:
                raw_text = parts[3]
                emotion = parts[-1]
                return raw_text, emotion
    return None

def save_features(speaker, basename, phonemes, durations):
    """ä¿å­˜ç‰¹å¾æ–‡ä»¶"""
    # Duration
    duration_path = f"preprocessed_data/ESD-Chinese/duration/{speaker}-duration-{basename}.npy"
    np.save(duration_path, np.array(durations))
    
    # å¯¹äºpitchå’Œenergyï¼Œå¦‚æœåŸæ–‡ä»¶å­˜åœ¨å°±å¤åˆ¶è°ƒæ•´ï¼Œå¦åˆ™ç”Ÿæˆé»˜è®¤å€¼
    pitch_path = f"preprocessed_data/ESD-Chinese/pitch/{speaker}-pitch-{basename}.npy"
    energy_path = f"preprocessed_data/ESD-Chinese/energy/{speaker}-energy-{basename}.npy"
    
    new_length = len(durations)
    
    if os.path.exists(pitch_path) and os.path.exists(energy_path):
        old_pitch = np.load(pitch_path)
        old_energy = np.load(energy_path)
        
        # æ’å€¼åˆ°æ–°é•¿åº¦
        if len(old_pitch) != new_length:
            indices = np.linspace(0, len(old_pitch)-1, new_length)
            new_pitch = np.interp(indices, np.arange(len(old_pitch)), old_pitch)
            new_energy = np.interp(indices, np.arange(len(old_energy)), old_energy)
        else:
            new_pitch = old_pitch
            new_energy = old_energy
    else:
        # ç”Ÿæˆé»˜è®¤å€¼
        new_pitch = np.random.normal(5.0, 1.0, new_length)
        new_energy = np.random.normal(0.5, 0.2, new_length)
    
    np.save(pitch_path, new_pitch)
    np.save(energy_path, new_energy)

if __name__ == "__main__":
    extract_ipa_data()
'''

    with open("reprocess_with_ipa.py", "w", encoding="utf-8") as f:
        f.write(script_content)
    
    print("åˆ›å»ºäº†é‡æ–°é¢„å¤„ç†è„šæœ¬: reprocess_with_ipa.py")

def main():
    print("ğŸµ åˆ›å»ºåŸºäºMFA IPAéŸ³ç´ çš„æ–°å¤„ç†ç³»ç»Ÿ")
    print("=" * 50)
    
    # 1. æ”¶é›†æ‰€æœ‰IPAéŸ³ç´ 
    ipa_phonemes = collect_all_ipa_phonemes()
    
    # 2. åˆ›å»ºæ–°çš„ç¬¦å·è¡¨
    create_ipa_symbols_file(ipa_phonemes)
    
    # 3. åˆ›å»ºIPAæ–‡æœ¬å¤„ç†å™¨
    create_ipa_text_processor()
    
    # 4. åˆ›å»ºé‡æ–°é¢„å¤„ç†è„šæœ¬
    create_preprocessing_script()
    
    print("\\nâœ… å®Œæˆï¼æ¥ä¸‹æ¥çš„æ­¥éª¤:")
    print("1. è¿è¡Œ: python reprocess_with_ipa.py")
    print("2. ä¿®æ”¹dataset.pyä½¿ç”¨æ–°çš„IPAå¤„ç†å™¨")
    print("3. ä¿®æ”¹ç¬¦å·è¡¨å¯¼å…¥")
    print("4. é‡æ–°è®­ç»ƒæ¨¡å‹")

if __name__ == "__main__":
    main() 