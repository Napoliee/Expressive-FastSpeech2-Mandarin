#!/usr/bin/env python3
"""
éªŒè¯MFAç”Ÿæˆçš„TextGridè´¨é‡
"""

import os
import json
import numpy as np
import librosa
import textgrid
from collections import Counter, defaultdict
import matplotlib.pyplot as plt
from tqdm import tqdm

def validate_single_textgrid(tg_path, wav_path, text_content=None):
    """éªŒè¯å•ä¸ªTextGridæ–‡ä»¶"""
    
    print(f"\n=== éªŒè¯æ–‡ä»¶: {os.path.basename(tg_path)} ===")
    
    # 1. è¯»å–éŸ³é¢‘æ—¶é•¿
    try:
        audio_duration = librosa.get_duration(filename=wav_path)
        print(f"éŸ³é¢‘æ—¶é•¿: {audio_duration:.3f}ç§’")
    except Exception as e:
        print(f"æ— æ³•è¯»å–éŸ³é¢‘: {e}")
        return None
    
    # 2. è¯»å–TextGrid
    try:
        tg = textgrid.TextGrid.fromFile(tg_path)
        print(f"TextGridæ—¶é•¿: {tg.maxTime:.3f}ç§’")
        print(f"å±‚æ•°: {len(tg.tiers)}")
        
        for i, tier in enumerate(tg.tiers):
            print(f"  å±‚{i}: {tier.name} ({len(tier)} intervals)")
    except Exception as e:
        print(f"æ— æ³•è¯»å–TextGrid: {e}")
        return None
    
    # 3. æ£€æŸ¥phoneså±‚
    phone_tier = None
    for tier in tg.tiers:
        if tier.name.lower() in ['phones', 'phone']:
            phone_tier = tier
            break
    
    if phone_tier is None:
        print("âŒ æœªæ‰¾åˆ°phoneså±‚")
        return None
    
    print(f"\nğŸ“± Phoneså±‚åˆ†æ:")
    print(f"éŸ³ç´ æ•°é‡: {len(phone_tier)}")
    
    # 4. éŸ³ç´ ç»Ÿè®¡
    phonemes = []
    durations = []
    empty_count = 0
    
    for interval in phone_tier:
        phone = interval.mark.strip()
        duration = interval.maxTime - interval.minTime
        
        if phone == '' or phone is None:
            empty_count += 1
        else:
            phonemes.append(phone)
            durations.append(duration)
    
    print(f"æœ‰æ•ˆéŸ³ç´ : {len(phonemes)}")
    print(f"ç©ºéŸ³ç´ : {empty_count}")
    
    if len(durations) > 0:
        print(f"å¹³å‡éŸ³ç´ æ—¶é•¿: {np.mean(durations):.3f}ç§’")
        print(f"æœ€çŸ­éŸ³ç´ : {np.min(durations):.3f}ç§’")
        print(f"æœ€é•¿éŸ³ç´ : {np.max(durations):.3f}ç§’")
        
        # æ£€æŸ¥å¼‚å¸¸çŸ­çš„éŸ³ç´ 
        short_phonemes = [(p, d) for p, d in zip(phonemes, durations) if d < 0.01]
        if short_phonemes:
            print(f"âš ï¸  å¼‚å¸¸çŸ­éŸ³ç´  (<0.01s): {len(short_phonemes)}ä¸ª")
            for p, d in short_phonemes[:5]:
                print(f"   {p}: {d:.4f}s")
    
    # 5. éŸ³ç´ ç±»å‹åˆ†æ
    phoneme_counter = Counter(phonemes)
    print(f"\nğŸ”¤ éŸ³ç´ ç±»å‹åˆ†æ:")
    print(f"å”¯ä¸€éŸ³ç´ æ•°: {len(phoneme_counter)}")
    print("æœ€å¸¸è§éŸ³ç´ :")
    for phone, count in phoneme_counter.most_common(10):
        print(f"  {phone}: {count}æ¬¡")
    
    # 6. æ—¶é—´è¿ç»­æ€§æ£€æŸ¥
    print(f"\nâ° æ—¶é—´è¿ç»­æ€§æ£€æŸ¥:")
    gaps = []
    overlaps = []
    
    for i in range(len(phone_tier) - 1):
        current_end = phone_tier[i].maxTime
        next_start = phone_tier[i+1].minTime
        diff = next_start - current_end
        
        if abs(diff) > 0.001:  # 1mså®¹å·®
            if diff > 0:
                gaps.append((i, diff))
            else:
                overlaps.append((i, -diff))
    
    print(f"æ—¶é—´é—´éš™: {len(gaps)}ä¸ª")
    print(f"æ—¶é—´é‡å : {len(overlaps)}ä¸ª")
    
    if gaps:
        print("å‰5ä¸ªé—´éš™:")
        for i, gap in gaps[:5]:
            print(f"  ä½ç½®{i}: {gap:.4f}s")
    
    # 7. è¾¹ç•Œæ£€æŸ¥
    first_start = phone_tier[0].minTime
    last_end = phone_tier[-1].maxTime
    
    print(f"\nğŸ“ è¾¹ç•Œæ£€æŸ¥:")
    print(f"é¦–éŸ³ç´ å¼€å§‹: {first_start:.3f}s")
    print(f"æœ«éŸ³ç´ ç»“æŸ: {last_end:.3f}s")
    print(f"è¦†ç›–èŒƒå›´: {last_end - first_start:.3f}s ({(last_end - first_start)/audio_duration*100:.1f}%)")
    
    # 8. æ–‡æœ¬å¯¹åº”åˆ†æï¼ˆå¦‚æœæä¾›ï¼‰
    if text_content:
        print(f"\nğŸ“ æ–‡æœ¬å¯¹åº”åˆ†æ:")
        print(f"åŸæ–‡: {text_content}")
        print(f"éŸ³ç´ åºåˆ—: {' '.join(phonemes)}")
        
        # ç®€å•çš„ä¸­æ–‡å­—ç¬¦vséŸ³ç´ æ¯”ä¾‹æ£€æŸ¥
        chinese_chars = len([c for c in text_content if '\u4e00' <= c <= '\u9fff'])
        if chinese_chars > 0:
            ratio = len(phonemes) / chinese_chars
            print(f"éŸ³ç´ /æ±‰å­—æ¯”ä¾‹: {ratio:.2f} (é€šå¸¸åœ¨1.5-3.0ä¹‹é—´)")
            if ratio < 1.0:
                print("âš ï¸  éŸ³ç´ æ•°é‡å¯èƒ½è¿‡å°‘")
            elif ratio > 5.0:
                print("âš ï¸  éŸ³ç´ æ•°é‡å¯èƒ½è¿‡å¤š")
    
    return {
        'audio_duration': audio_duration,
        'textgrid_duration': tg.maxTime,
        'phoneme_count': len(phonemes),
        'empty_count': empty_count,
        'unique_phonemes': len(phoneme_counter),
        'avg_duration': np.mean(durations) if durations else 0,
        'gaps': len(gaps),
        'overlaps': len(overlaps),
        'coverage': (last_end - first_start) / audio_duration if audio_duration > 0 else 0
    }

def batch_validate_textgrids():
    """æ‰¹é‡éªŒè¯TextGridæ–‡ä»¶"""
    
    print("=== æ‰¹é‡éªŒè¯TextGridè´¨é‡ ===")
    
    textgrid_dir = "preprocessed_data/ESD-Chinese/TextGrid"
    raw_data_dir = "raw_data/ESD-Chinese"
    
    results = []
    phoneme_global_counter = Counter()
    
    # é€‰æ‹©ä¸€äº›æ ·æœ¬è¿›è¡Œæ£€æŸ¥
    sample_files = []
    for speaker in ['0001', '0003', '0008']:
        speaker_tg_dir = os.path.join(textgrid_dir, speaker)
        if os.path.exists(speaker_tg_dir):
            tg_files = [f for f in os.listdir(speaker_tg_dir) if f.endswith('.TextGrid')]
            # æ¯ä¸ªè¯´è¯äººå–å‰5ä¸ªæ–‡ä»¶
            sample_files.extend([(speaker, f) for f in tg_files[:5]])
    
    print(f"å°†æ£€æŸ¥ {len(sample_files)} ä¸ªæ ·æœ¬æ–‡ä»¶")
    
    for speaker, tg_file in tqdm(sample_files):
        basename = tg_file.replace('.TextGrid', '')
        
        tg_path = os.path.join(textgrid_dir, speaker, tg_file)
        wav_path = os.path.join(raw_data_dir, speaker, f"{basename}.wav")
        lab_path = os.path.join(raw_data_dir, speaker, f"{basename}.lab")
        
        # è¯»å–æ–‡æœ¬å†…å®¹
        text_content = None
        if os.path.exists(lab_path):
            with open(lab_path, 'r', encoding='utf-8') as f:
                text_content = f.read().strip()
        
        result = validate_single_textgrid(tg_path, wav_path, text_content)
        if result:
            result['speaker'] = speaker
            result['basename'] = basename
            results.append(result)
            
            # æ”¶é›†éŸ³ç´ ç»Ÿè®¡
            try:
                tg = textgrid.TextGrid.fromFile(tg_path)
                phone_tier = None
                for tier in tg.tiers:
                    if tier.name.lower() in ['phones', 'phone']:
                        phone_tier = tier
                        break
                        
                if phone_tier:
                    for interval in phone_tier:
                        phone = interval.mark.strip()
                        if phone and phone != '':
                            phoneme_global_counter[phone] += 1
            except:
                pass
    
    # 7. æ€»ä½“ç»Ÿè®¡
    print(f"\n{'='*50}")
    print("ğŸ“Š æ€»ä½“è´¨é‡ç»Ÿè®¡")
    print(f"{'='*50}")
    
    if results:
        coverage_values = [r['coverage'] for r in results]
        phoneme_counts = [r['phoneme_count'] for r in results]
        durations = [r['avg_duration'] for r in results]
        
        print(f"å¹³å‡è¦†ç›–ç‡: {np.mean(coverage_values):.3f} Â± {np.std(coverage_values):.3f}")
        print(f"å¹³å‡éŸ³ç´ æ•°: {np.mean(phoneme_counts):.1f} Â± {np.std(phoneme_counts):.1f}")
        print(f"å¹³å‡éŸ³ç´ æ—¶é•¿: {np.mean(durations):.3f} Â± {np.std(durations):.3f}ç§’")
        
        # é—®é¢˜æ£€æµ‹
        low_coverage = [r for r in results if r['coverage'] < 0.8]
        high_gaps = [r for r in results if r['gaps'] > 5]
        
        print(f"\nâš ï¸  æ½œåœ¨é—®é¢˜:")
        print(f"ä½è¦†ç›–ç‡æ–‡ä»¶ (<80%): {len(low_coverage)}")
        print(f"é«˜é—´éš™æ–‡ä»¶ (>5ä¸ª): {len(high_gaps)}")
        
        if low_coverage:
            print("ä½è¦†ç›–ç‡æ–‡ä»¶:")
            for r in low_coverage[:3]:
                print(f"  {r['speaker']}_{r['basename']}: {r['coverage']:.2f}")
    
    # 8. å…¨å±€éŸ³ç´ ç»Ÿè®¡
    print(f"\nğŸŒ å…¨å±€éŸ³ç´ ç»Ÿè®¡:")
    print(f"æ€»éŸ³ç´ ç±»å‹: {len(phoneme_global_counter)}")
    print("æœ€å¸¸è§éŸ³ç´ :")
    for phone, count in phoneme_global_counter.most_common(15):
        print(f"  {phone}: {count}")
    
    # 9. ç”Ÿæˆè´¨é‡æŠ¥å‘Š
    generate_quality_report(results, phoneme_global_counter)

def generate_quality_report(results, phoneme_counter):
    """ç”Ÿæˆè´¨é‡æŠ¥å‘Š"""
    
    report = {
        'summary': {
            'total_files': len(results),
            'avg_coverage': np.mean([r['coverage'] for r in results]),
            'avg_phonemes': np.mean([r['phoneme_count'] for r in results]),
            'total_phoneme_types': len(phoneme_counter)
        },
        'phoneme_distribution': dict(phoneme_counter.most_common(20)),
        'quality_issues': {
            'low_coverage': [r for r in results if r['coverage'] < 0.8],
            'high_gaps': [r for r in results if r['gaps'] > 5],
            'short_files': [r for r in results if r['phoneme_count'] < 5]
        }
    }
    
    with open('textgrid_quality_report.json', 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“„ è´¨é‡æŠ¥å‘Šå·²ä¿å­˜åˆ°: textgrid_quality_report.json")

def visualize_sample_textgrid(speaker="0001", file_index=0):
    """å¯è§†åŒ–å•ä¸ªTextGridæ–‡ä»¶"""
    
    textgrid_dir = "preprocessed_data/ESD-Chinese/TextGrid"
    raw_data_dir = "raw_data/ESD-Chinese"
    
    speaker_dir = os.path.join(textgrid_dir, speaker)
    tg_files = [f for f in os.listdir(speaker_dir) if f.endswith('.TextGrid')]
    
    if file_index >= len(tg_files):
        print(f"æ–‡ä»¶ç´¢å¼•è¶…å‡ºèŒƒå›´ï¼Œæœ€å¤§ç´¢å¼•: {len(tg_files)-1}")
        return
    
    tg_file = tg_files[file_index]
    basename = tg_file.replace('.TextGrid', '')
    
    tg_path = os.path.join(speaker_dir, tg_file)
    wav_path = os.path.join(raw_data_dir, speaker, f"{basename}.wav")
    
    print(f"å¯è§†åŒ–æ–‡ä»¶: {speaker}_{basename}")
    
    # è¯»å–éŸ³é¢‘
    y, sr = librosa.load(wav_path)
    
    # è¯»å–TextGrid
    tg = textgrid.TextGrid.fromFile(tg_path)
    phone_tier = None
    for tier in tg.tiers:
        if tier.name.lower() in ['phones', 'phone']:
            phone_tier = tier
            break
    
    if phone_tier is None:
        print("æœªæ‰¾åˆ°phoneså±‚")
        return
    
    # ç»˜åˆ¶æ³¢å½¢å’ŒéŸ³ç´ æ ‡æ³¨
    plt.figure(figsize=(15, 8))
    
    # ä¸Šéƒ¨åˆ†ï¼šæ³¢å½¢
    plt.subplot(2, 1, 1)
    time_axis = np.linspace(0, len(y)/sr, len(y))
    plt.plot(time_axis, y)
    plt.title(f'Audio Waveform: {speaker}_{basename}')
    plt.ylabel('Amplitude')
    
    # æ·»åŠ éŸ³ç´ è¾¹ç•Œçº¿
    for interval in phone_tier:
        plt.axvline(x=interval.minTime, color='red', alpha=0.5, linestyle='--')
        plt.axvline(x=interval.maxTime, color='red', alpha=0.5, linestyle='--')
    
    # ä¸‹éƒ¨åˆ†ï¼šéŸ³ç´ æ ‡æ³¨
    plt.subplot(2, 1, 2)
    for i, interval in enumerate(phone_tier):
        start_time = interval.minTime
        end_time = interval.maxTime
        phone = interval.mark.strip()
        
        # ç»˜åˆ¶éŸ³ç´ åŒºé—´
        plt.barh(0, end_time - start_time, left=start_time, height=0.8, 
                alpha=0.7, color=plt.cm.Set3(i % 12))
        
        # æ·»åŠ éŸ³ç´ æ ‡ç­¾
        mid_time = (start_time + end_time) / 2
        if phone and phone != '':
            plt.text(mid_time, 0, phone, ha='center', va='center', 
                    fontsize=8, rotation=90)
    
    plt.xlim(0, len(y)/sr)
    plt.ylim(-0.5, 0.5)
    plt.ylabel('Phonemes')
    plt.xlabel('Time (s)')
    plt.title('Phoneme Alignment')
    
    plt.tight_layout()
    plt.savefig(f'textgrid_visualization_{speaker}_{basename}.png', dpi=150)
    plt.show()
    
    print(f"å¯è§†åŒ–å›¾ç‰‡å·²ä¿å­˜: textgrid_visualization_{speaker}_{basename}.png")

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser()
    parser.add_argument("--mode", choices=["single", "batch", "visualize"], 
                       default="batch", help="éªŒè¯æ¨¡å¼")
    parser.add_argument("--speaker", default="0001", help="è¯´è¯äººID")
    parser.add_argument("--file_index", type=int, default=0, help="æ–‡ä»¶ç´¢å¼•")
    args = parser.parse_args()
    
    if args.mode == "batch":
        batch_validate_textgrids()
    elif args.mode == "visualize":
        visualize_sample_textgrid(args.speaker, args.file_index)
    else:
        # Single mode - è¿™é‡Œå¯ä»¥æ·»åŠ å•æ–‡ä»¶éªŒè¯é€»è¾‘
        print("å•æ–‡ä»¶éªŒè¯æ¨¡å¼") 